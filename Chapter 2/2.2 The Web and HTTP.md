### 1. Overview of HTTP

* HTTP is the Web’s application-layer protocol.
* HTTP is implemented in two programs: a client program and a server program.
* The client program and server program, executing on different end systems, talk to each other by exchanging HTTP messages.
* Web terminology
	* A Web page (also called a document) consists of objects.
	* An object is simply a file—such as an HTML file, a JPEG image, a Javascrpt file, a CCS style sheet file, or a video clip—that is addressable by a single URL.
	* Most Web pages consist of a base HTML file and several referenced objects.
	* Each URL has two components: the hostname of the server that houses the object and the object’s path name.
	* Web browsers (such as Firefox, Edge, Chrome) implement the client side of HTTP. Hence in the context of the Web, the words browser and client are used interchangeably.
	* Web servers (such as Apache and Microsoft Internet Information Server) implement the server side of HTTP and house Web objects - each addressable by a URL.
* HTTP defines how Web clients/browsers request Web pages from Web servers and how servers transfer Web pages to clients.
* The Web uses the client-server application architecture - A Web server is always on, with a fixed IP address, and it services requests from potentially millions of different browsers.
* HTTP uses TCP as its underlying transport protocol.
	* The HTTP client first initiates a TCP connection with the server.
 	* Once the connection is established, the browser and the server processes access TCP through their socket interfaces.
  	* TCP provides reliable data transfer service to HTTP - each HTTP request message sent by a client process eventually arrives intact at the server; similarly, each HTTP response message sent by the server process eventually arrives intact at the client.
* The server sends requested files to clients without storing any state information about the client.
* As an HTTP server maintains no information about the clients, HTTP is said to be a stateless protocol.

***

### 2. Non-Persistent and Persistent Connections

* When this client-server interaction is taking place over TCP, the application developer needs to make an important decision—should each request/response pair be sent over a separate TCP connection, or should all of the requests and their corresponding responses be sent over the same TCP connection?
* The application is using non-persistent connections in the former approach and persistent connections in the latter approach.
* HTTP uses persistent connections in its default mode, however HTTP clients and servers can be configured to use non-persistent connections instead.

###### HTTP with Non-Persistent Connections
* In case of non-persistant connections, the seperate TCP connection is used for every request/response interaction between the client and the server.
* Hence, if a client requests for a web page with 1 base HTML file and 10 images, then a total of 11 TCP connections will be used as each non-persistent TCP connection transports exactly one request message and one response message.
* HTTP/1.0 employes non-persistent TCP connections.
* Users can configure some browsers to control the degree of parallelism.
	* Browsers may open multiple TCP connections and request different parts of the Web page over the multiple connections.
 	* This helps reduce the response time
* Assuming RTT represents the Round Trip Time for one packet to go from the client to the server and back to the client, then for each TCP connection, the following delays are involved:
	* Three-way TCP handshake - the client sends a small TCP segment to the server, the server acknowledges and responds with a small TCP segment, and, finally, the client acknowledges back to the server.
 	* The first two parts take up one RTT.
  	* The client sends the HTTP request message with its ACK in the second RTT.
  	* The server then sends the HTML file into the TCP connection.
  	* This takes up another RTT plus transmission time for the server to send the entire file.
	* Therefore, the total response time is roughly two RTTs plus the transmission time at the server.

###### HTTP with Persistent Connections
* Non-persistent connections have some shortcomings:
	* A brand-new TCP connection must be established and maintained for each requested object.
 	* For each of these connections, TCP buffers must be allocated and TCP variables must be kept in both the client and server, leading to increased overheads.
  	* Each object suffers a delivery delay of two RTTs—one RTT to establish the TCP connection and one RTT to request and receive an object.
* With HTTP/1.1 persistent connections, the server leaves the TCP connection open after sending a response.
* Hence, subsequent requests and responses between the same client and server can be sent over the same connection.
* Therefore, the entire web page with 1 base HTML file and 10 images can be sent over a single persistent TCP connection.
* Moreover, multiple Web pages residing on the same server can be sent from the server to the same client over a single persistent TCP connection.
* These requests for objects can be made back-to-back, without waiting for replies to pending requests (pipelining).
	* When the server receives the back-to-back requests, it sends the objects back-to-back.
	* The default mode of HTTP uses persistent connections with pipelining.
* Typically, the HTTP server closes a connection when it isn’t used for a certain time (a configurable timeout interval).

*** 

### 3. HTTP Message Format

###### HTTP Request Message
* Below we provide a typical HTTP request message:
```
GET /somedir/page.html HTTP/1.1
Host: www.someschool.edu
Connection: close
User-agent: Mozilla/5.0
Accept-language: fr
```
* The first line of an HTTP request message is called the request line.
	* The request line has three fields: the method field (`GET`), the URL field (`/somedir/page.html`), and the HTTP version field (`HTTP/1.1`).
 	* The method field can take on several different values, including `GET`, `POST`, `HEAD`, `PUT`, and `DELETE`.
* The subsequent lines are called the header lines
	* The header line `Host: www.someschool.edu` specifies the host on which the object resides.
	* By including the `Connection: close` header line, the browser is telling the server that it wants the server to close the connection after sending the requested object (hence it's a non-persistent connection).
	* The `User-agent: Mozilla/5.0` header line specifies the user agent - the browser type that is making the request to the server.
	* This header line is useful because the server can actually send different versions of the same object to different types of user agents.
	* Finally, the `Accept-language: fr` header indicates that the user prefers to receive a French version of the object (if available, else the default version).
* Some HTTP messages also have entity body after the header lines
	* An HTTP client often uses the `POST` method when the user fills out a form (for example, when a user provides search words to a search engine).
 	* With a `POST` message, the user is still requesting a Web page from the server, but the specific contents of the Web page depend on what the user entered into the form fields.
  	* If the value of the method field is `POST`, then the entity body contains what the user entered into the form fields.
  	* A request generated with a form does not necessarily have to use the `POST` method. Instead, HTML forms often use the `GET` method and include the inputted data (in the form fields) in the requested URL (in the format of `URL?Input1&Input2`).
* Other HTTP Request methods
	* When a server receives a request with the `HEAD` method, it responds with an HTTP message but it leaves out the requested object, making it useful for debugging.
 	* The `PUT` method allows a user to upload an object to a specific path (directory) on a specific Web server (often used with Web publishing tools).
  	* The `PUT` method is also used by applications that need to upload objects to Web servers.
  	* The `DELETE` method allows a user, or an application, to delete an object on a Web server.

###### HTTP Response Message
* Below is a typical HTTP response message:
```
HTTP/1.1 200 OK
Connection: close
Date: Tue, 18 Aug 2015 15:44:04 GMT
Server: Apache/2.2.3 (CentOS)
Last-Modified: Tue, 18 Aug 2015 15:11:03 GMT
Content-Length: 6821
Content-Type: text/html
(data data data data data ...)
```
* The first line in the HTTP response message is a status line:
	* It three fields: the protocol version (`HTTP/1.1`), a status code (`200`), and a corresponding status message(`OK`).
 	* Following are a few common status codes and associated phrases:
  		* `200 OK` - Request succeeded and the information is returned in the response
		* `301 Moved Permanently` - Requested object has been permanently moved; the new URL is specified in `Location: NEW_URL` header of the response message. The client software will automatically retrieve the new URL.
  		* `304 Not Modified` - The requested object has not been modified since the last time it was accessed (by the cache).
    	* `400 Bad Request` - This is a generic error code indicating that the request could not be understood by the server.
     	* `404 Not Found` - The requested document does not exist on this server.
      	* `505 HTTP Version Not Supported` - The requested HTTP protocol version is not supported by the server.
* The next few lines are header lines:
	* The `Connection: close` header line indicates that the server is going to close the TCP connection after sending the message.
 	* The `Date:` header line indicates the time and date when the HTTP response was created and sent by the server.
  	* The `Last-Modified:` header line indicates the time and date when the object was created or last modified. It is critical for object caching, both in the local client and in network cache servers (also known as proxy servers).
  	* The `Server: Apache/2.2.3 (CentOS)` header line indicates that the message was generated by an Apache Web server; it is analogous to the `User-agent:` header line in the HTTP request message.
  	* The `Content-Length:` header line indicates the number of bytes in the object being sent.
  	* The `Content-Type: text/html` header line indicates that the object in the entity body is HTML text.
* After the headers is the entity body, which contains the requested object (in that case, the HTML file).

Refer to [the sample request and response headers](https://github.com/violet-autumn/Computer-Networking/blob/main/Chapter%202/Additional%20texts.md#http-request-and-response-texts) to check out actual HTTP Request and Response headers. 

***

### 4. User-Server Interaction: Cookies

* As mentioned earlier, an HTTP server is stateless - this simplifies server design and helps develop high-performance Web servers that can handle thousands of simultaneous TCP connections.
* However, it is often desirable for a Web site to identify users, either because the server wishes to restrict user access or because it wants to serve content as a function of the user identity.
* For these purposes, HTTP uses cookies - which allow sites to keep track of users.
* Cookie technology has four components:
	* A cookie header line in the HTTP response message when the cookie is set by the web site (`Set-cookie: ***`)
 	* A cookie header line in the HTTP request message when the cookie is then referenced everytime the user interacts with the web site (`Cookie: ***`)
  	* A cookie file kept on the user’s end system and managed by the user’s browser
  	* A back-end database at the Web site which takes actions based on the cookie
* The [sample request and response headers](https://github.com/violet-autumn/Computer-Networking/blob/main/Chapter%202/Additional%20texts.md#http-request-and-response-texts) contain both the headers.
* The following diagram explains the cookie setting process and subsequent usage:
<img width="800" alt="image" src="https://github.com/user-attachments/assets/ab7891b8-c0ef-437e-85b1-d903c3538e7b" />

* Therefore, by using cookier, a web server is able to track the user's activity.
	* For example, this is used by e-comm websites to track the pages a user has visited and the items added in the cart.
	* This helps the e-comm website recommend items and provide one-click payment for all the items together in the end (even without logging in - called the guest checkout feature).
	* If the user registers after adding items in the cart, the server can then map the registration details (full name, e-mail address, postal address, and credit card information) in its database, thereby associating the user's account with their cookie.
 	* Even after logging-in, cookies can be used to -
  		* Maintain authentication throughout the session so the user doesn't need to re-login.
    	* Implementing a "Remember Me" or "Stay Signed in" functionality, where even if the user closes the browser, they are automatically logged in the next time they open the web site. 
     	* Tracking user behavior, storing preferences, and providing personalized content.  
* Cookies can thus be used to create a user session layer on top of stateless HTTP, permitting the server to identify the user throughout the user’s session with the application.
* However, cookies are controversial because they can also be considered as an invasion of privacy - by using a combination of cookies and user-supplied account information, a web site can learn a lot about a user and potentially sell this information to a third party.

***

### 5. Web Caching

* A Web cache—also called a proxy server—is a network entity that satisfies HTTP requests on the behalf of an origin Web server.
* The Web cache has its own disk storage and keeps copies of recently requested objects in this storage.
* A user’s browser can be configured so that all of the user’s HTTP requests are first directed to the Web cache.
* Following is how a Web cache fits in the network:
	* The browser establishes a TCP connection to the Web cache and sends an HTTP request for the object to the Web cache.
 	* The Web cache checks to see if it has a copy of the object stored locally. If it does, the Web cache returns the object within an HTTP response message to the client browser.
  	* If the Web cache does not have the object, the Web cache opens a TCP connection to the origin server.
  	* The Web cache then sends an HTTP request for the object into the cache-to-server TCP connection.
  	* The origin server sends the object within an HTTP response to the Web cache.
  	* Web cache stores a copy in its local storage and sends a copy, within an HTTP response message, to the client browser (over the existing TCP connection between the client browser and the Web cache).
* Note that a cache is both a server and a client at the same time.
* Typically a Web cache is purchased and installed by an ISP.
	* For example, a university might install a cache on its campus network and configure all of the campus browsers to point to the cache.
 	* A major residential ISP might install one or more caches in its network and preconfigure its shipped browsers to point to the installed caches.
  	* Content provider networks (like Google) install various geographically distributed web cache servers worldwide to minimize latency and improve content delivery speed for users.

###### Advantages of Web Caching
* A Web cache can substantially reduce the response time for a client request.
	* The origin server can be far away geographically while the cache server is often much closer to the end-user.
	* The bottleneck bandwidth between client-origin server is often much less than the bottleneck bandwidth between the client-cache server, leading to much faster access. Particularly, in case the web cache is in the LAN network like in the case of an institution (university or corporate).
  	* Through Content Delivery Networks (CDNs), Web caches localize much of the traffic on the network, leading to lower latency.
  		* Shared CDNs - Akamai and Limelight
  	 	* Dedicated CDNs - Google and Netflix
* Web caches can substantially reduce traffic on an institution’s access link to the Internet.
	* By reducing traffic, the institution does not have to upgrade bandwidth as quickly, thereby reducing costs.
* Web caches can substantially reduce Web traffic in the Internet as a whole, thereby improving performance for all applications.

###### The Conditional GET
* Although caching can reduce user-perceived response times, it introduces a new problem—the copy of an object residing in the cache may be stale. That is, the object housed in the Web server may have been modified since the copy was cached at the client.
* HTTP has a mechanism that allows a cache to verify that its objects are up to date.
* This mechanism is called the conditional GET.
* Following is how the conditional GET is used -
	* On the behalf of a requesting browser, the proxy cache sends a request message to a Web server [1]
 	* The Web server sends a response message with the requested object to the cache [2]
  	* The cache forwards the object to the requesting browser but also caches the object locally. Importantly, the cache also stores the last-modified date along with the object.
  	* Some time later, another browser requests the same object via the cache, and the object is still in the cache. Since this object may have been modified at the Web server in the time since the cache accessed it, the cache performs an up-to-date check by issuing a conditional GET [3].
  		* Note that the value of the `If-modified-since:` header line is exactly equal to the value of the `Last-Modified:` header line that was sent by the server when the content was originally loaded.
  	 	* If the content has not been modified, the web server sends a `304 Not Modified` response with an empty body [4], which tells the cache that it can go ahead and forward its cached copy of the object to the requesting browser.
  	  	* If the content has been modified, the web server sends the updated file.

[1]
```
GET /wiki/Russet_sparrow HTTP/1.1
Host: en.wikipedia.org
```
[2]
```
HTTP/1.1 200 OK
Date: Sat, 3 Oct 2015 15:39:29
Server: Apache/1.3.0 (Unix)
Last-Modified: Wed, 9 Sep 2015 09:23:24
Content-Type: text/html
(data data data data data ...)
```
[3]
```
GET /wiki/Russet_sparrow HTTP/1.1
Host: en.wikipedia.org
If-modified-since: Wed, 9 Sep 2015 09:23:24
```
[4]
```
HTTP/1.1 304 Not Modified
Date: Sat, 10 Oct 2015 15:39:29
Server: Apache/1.3.0 (Unix)
(empty entity body)
```

***

### 6. HTTP/2

* HTTP/2 standardized in 2015, was the first new version of HTTP since HTTP/1.1, which was standardized in 1997.
* Since standardization, HTTP/2 has taken off, with over 40% of the top 10 million websites supporting HTTP/2 in 2020 [W3Techs].
* Most browsers—including Google Chrome, Internet Explorer, Safari, Opera, and Firefox—also support HTTP/2.
* The primary goals for HTTP/2 are to:
	* Reduce perceived latency by enabling request and response multiplexing over a single TCP connection
 	* Provide request prioritization and server push
  	* Provide efficient compression of HTTP header fields.
* HTTP/2 does not change HTTP methods, status codes, URLs, or header fields. Instead, it changes how the data is formatted and transported between the client and server.

###### Head-of-Line Blocking
* HTTP/1.1 uses persistent TCP connections, allowing a Web page to be sent from server to client over a single TCP connection.
	* By having only one TCP connection per Web page, the number of sockets at the server is reduced and each transported Web page gets a fair share of the network bandwidth.
* However, sending all the objects of a Web page over a single TCP connection has a Head of Line (HOL) blocking problem.
	* For example, suppose a Web page includes an HTML base page, a large video clip near the top of Web page, and many small objects below the video.
 	* Using a single TCP connection, the video clip will take a long time to reach the client (especially if access bandwidth is low), while the small objects are delayed as they wait behind the video clip.
  	* In this case, the video file is at the head of teh line and blocking the otehr smaller objects.
* HTTP/1.1 browsers typically work around this problem by opening multiple parallel TCP connections, thereby having objects in the same web page sent in parallel to the browser.
	* This way, the small objects can arrive at and be rendered in the browser much faster, thereby reducing user-perceived delay.
	* TCP congestion control also provides browsers an unintended incentive to use multiple parallel TCP connections rather than a single persistent connection.
 		* Roughly speaking, TCP congestion control aims to give each TCP connection sharing a bottleneck link an equal share of the available bandwidth of that link (so n links get 1/n<sup>th</sup> of the bandwidth.
   		* But by opening multiple parallel TCP connections to transport a single Web page, the browser can “cheat” and grab a larger portion of the link bandwidth.
     	* Many HTTP/1.1 browsers open up to six parallel TCP connections not only to circumvent HOL blocking but also to obtain more bandwidth.
* One of the primary goals of HTTP/2 is to get rid of (or at least reduce the number of) parallel TCP connections for transporting a single Web page.
	* This not only reduces the number of sockets that need to be open and maintained at servers, but also allows TCP congestion control to operate as intended.
 	* This is done by enabling request and response multiplexing over a single TCP connection.

###### HTTP/2 Framing
* The HTTP/2 solution for HOL blocking is to break each message into small frames, and interleave the request and response messages on the same TCP connection.
	* For example, there is a Web page consisting of one large video clip and, say, 8 smaller objects.
 	* Thus the server will receive 9 concurrent requests from any browser wanting to see this Web page.
  	* For each of these requests, the server needs to send 9 competing HTTP response messages to the browser.
  	* Suppose all frames are of fixed length, with the video clip being of 1000 frames, and the small objects being 2 frames each.
  	* With frame interleaving, after sending one frame from the video clip, the first frames of each of the small objects are sent.
  	* Then after sending the second frame of the video clip, the last frames of each of the small objects are sent.
  	* Thus, all of the smaller objects are sent after sending a total of 18 frames. If interleaving were not used, the smaller objects would be sent only after sending 1000 frames.
* The ability to break down an HTTP message into independent frames, interleave them, and then reassemble them on the other end is the single most important enhancement of HTTP/2.
	* The framing is done by the framing sub-layer of the HTTP/2 protocol.
 	* When a server wants to send an HTTP response, the response is processed by the framing sub-layer, where it is broken down into frames.
  	* The header field of the response becomes one frame, and the body of the message is broken down into one for more additional frames.
  	* The frames of the response are then interleaved by the framing sub-layer in the server with the frames of other responses and sent over the single persistent TCP connection.
  	* As the frames arrive at the client, they are first reassembled into the original response messages at the framing sub-layer and then processed by the browser as usual.
  	* Similarly, a client’s HTTP requests are broken into frames and interleaved.
* In addition to breaking down each HTTP message into independent frames, the framing sublayer also binary encodes the frames. Binary protocols are more efficient to parse, lead to slightly smaller frames, and are less error-prone.

###### Response Message Prioritization and Server Pushing

* Message prioritization allows developers to customize the relative priority of requests to better optimize application performance.
	* The framing sub-layer organizes messages into parallel streams of data.
 	* When a client sends concurrent requests to a server, it can prioritize the responses it is requesting by assigning a weight between 1 and 256 to each message to indicate priority.
  	* Using these weights, the server can send first the frames for the responses with the highest priority.
	* The client also states each message’s dependency on other messages by specifying the ID of the message on which it depends.
* Another feature of HTTP/2 is the ability for a server to send multiple responses for a single client request.
 	* The HTML base page indicates the objects that will be needed to fully render the Web page.
  	* So instead of waiting for the HTTP requests for these objects, the server can analyze the HTML page, identify the objects that are needed, and send them to the client before receiving explicit requests for these objects.
  	* Server push hence eliminates the extra latency due to waiting for the requests.

###### HTTP/3
* As noted earlier, HTTP/2 solves the problem of HTTP-transaction-level head-of-line blocking problem by allowing multiple concurrent HTTP transactions multiplexed over a single TCP connection.
* However, as the parallel nature of HTTP/2's multiplexing is not visible to TCP's loss recovery mechanisms, a lost or reordered packet causes all active transactions to experience a stall (until the missing packet is retransmitted) regardless of whether that transaction was impacted by the lost packet - known as TCP head-of-line blocking.
* QUIC (Quick UDP Internet Connections) is a new “transport” protocol that is implemented in the application layer over the bare-bones UDP protocol, and HTTP/3 is yet a new HTTP protocol that is designed to operate over QUIC.
	* HTTP/3 uses similar semantics compared to earlier revisions of the protocol, including the same request methods, status codes, and message fields, but encodes them and maintains session state differently.
	* QUIC allows each stream to be independently delivered. Therefore, packet loss in one stream doesn’t block others.
 	* This resolves the TCP level head-of-line blocking issue with HTTP/2.
	* QUIC has several features that are desirable for HTTP, such as message multiplexing (interleaving), per-stream flow control, and low-latency connection establishment.
 	* Many of the HTTP/2 features (such as message interleaving) are subsumed by QUIC, allowing for a simpler, streamlined design for HTTP/3.
* QUIC will be covered in more detail in Chapter 3.

***
