### 1. Overview of Delay in Packet-Switched networks

#### 1.1 Types of Delay

* As a packet from one host to another via a series of routers, it suffers certian delays at every node (nodal delay):
	* Processing delay 
 	* Queuing delay
  	* Transmission delay
  	* Propogation delay

<img width="800" alt="image" src="https://github.com/user-attachments/assets/5ff3ca66-6487-47b1-ad24-93cc2fe71591" />

###### Processing delay
* Time required to examine the packet’s header and determine where to direct the packet.
* Also includes time needed to check for bit-level errors in the packet that occurred in transmitting the packet’s bits from the upstream node.
* Processing delays in high-speed routers are typically on the order of microseconds or less.

###### Queuing delay
* After this processing, the router directs the packet to the queue that precedes the link to next node, where the packet experiences queuing delay.
* The length of the queuing delay of a specific packet will depend on the number of earlier-arriving packets that are queued and waiting for transmission onto
the link, ranging from zero wait time if the queue is empty to longer wait times if the traffic is heavy.
* Queuing delays can be on the order of microseconds to milliseconds in practice.

###### Transmission delay
* The amount of time required to push (that is, transmit) all of the packet’s bits into the link is the transmission delay.
* As seen [earlier](https://github.com/violet-autumn/Computer-Networking/blob/main/Chapter%201/1.3%20The%20Network%20Core.md#store-and-forward-packet-switching), if we denote the length of the packet by L bits, and the transmission rate of the outbound link as R bits/sec, then the transmission delay is d<sub>trans</sub>=L/R.
* Transmission delays are typically on the order of microseconds to milliseconds in practice.

###### Propogation delay
* The time required to propagate from the beginning of the outbound link to next node is the propagation delay.
* The bit propagates at the propagation speed of the link, which depends on the physical medium of the link, and is in the range of 2x10<sup>^8</sup> meters/sec to 3x10<sup>^8</sup> meters/sec.
* The propagation delay can be represented by d/s, where d is the distance between two nodes and s is the propogation speed.
* In wide-area networks, propagation delays are on the order of milliseconds.

#### 1.2 Comparing Transmission and Propagation Delay

* The total nodal delay is given by d<sub>nodal</sub> = d<sub>proc</sub> + d<sub>queue</sub> + d<sub>trans</sub> + d<sub>prop</sub>
* The contribution of these delay components can vary significantly.
	* d<sub>prop</sub> can be negligible for a link connecting two routers on the same university campus; however, it could be hundreds of milliseconds for two routers interconnected by a geostationary satellite link, and become the dominant term in d<sub>nodal</sub>.
 	* Similarly, d<sub>trans</sub> can range from negligible to significant. Its contribution is typically negligible for transmission rates of 10 Mbps and higher (for
example, for LANs); however, it can be hundreds of milliseconds for large Internet packets sent over low-speed dial-up modem links.
	* The processing delay, d<sub>proc</sub>, is often negligible; however, it strongly influences a router’s maximum throughput - the maximum rate at which a router can forward packets.
* If transmission delay is high and propogation delay is low, it can happen that the first bits of packet reach the next node before the last bits of the packet are even transmitted.

***

### 2. Queuing Delay and Packet Loss

* Unlike the other three delays, the queuing delay can vary from packet to packet.
	* Eg: If 10 packets arrive at an empty queue at the same time, the first packet transmitted will suffer no queuing delay, while the last packet transmitted will suffer a relatively large queuing delay.
* Therefore, we use statistical measures (like average queuing delay, probablity that the delay will exceed a given value) when characterizing queuing delay.
* Queuing delay depends upon:
	* Rate at which traffic arrives at the queue (let a packets/second be the average rate at which packets arrive)
 	* Transmission rate of the link (let R bits/second be the outbound transmission rate)
  	* Nature of the arriving traffic (periodic or in spurts)

###### Traffic Intensity
* Let L bits be the size of the packets, then the bits arrive at the queue at the rate of La bits/second.
* Traffic Intensity is defined as $\frac{La}{R}$, and it plays a crucial role in designing systems to minimise queuing delay.
	* If $\frac{La}{R}$ > 1, the average rate at which bits arrive at the queue exceeds the rate at which the bits can be transmitted from the queue - leading to increase in queue size and queuing delay (and eventually causing packet loss).
 	* If $\frac{La}{R}$ ≤ 1, the nature of arriving traffic plays a role:
  		* If packets arrive periodically—that is, say one packet arrives every L/R seconds—then every packet will arrive at an empty queue and there will be no queuing delay.
    	* If packets arrive in bursts (of say P packets every $\frac{PL}{R}$ seconds), then the first packet will face no queuing delay, while the last one will be delayed by $\frac{(P-1)L}{R}$ seconds.
* Typically, the arrival process to a queue is random. In this more realistic case, the quantity $\frac{La}{R}$ is not usually sufficient to fully characterize the queuing delay statistics.
* Nonetheless, it is useful in gaining an intuitive understanding of the extent of the queuing delay.
	* If traffic intensity is close to zero, then packet arrivals are few and far between and it is unlikely that an arriving packet will find another packet in the queue, and hence the queuing delay will be close to zero.
 	* If traffic intensity is close to one:
  		* There will be intervals of time when the arrival rate exceeds the transmission capacity (due to variations in packet arrival rate), and a queue will form during these periods of time.
    	* When the arrival rate is less than the transmission capacity, the length of the queue will shrink.
     	* As the traffic intensity approaches one, the average queue length gets larger and larger, and the average queuing delay increases rapidly. A small percentage increase in the intensity will result in a much larger percentage-wise increase in delay.

###### Packet Loss
* As the queue preceding a link has finite capacity, packet delays do not really keep increasing and approach infinity as the traffic intensity approaches 1.
* Instead, a packet can arrive to find a full queue, and with no place to store such a packet, a router will drop that packet.
* From an end-system viewpoint, a packet loss will look like a packet having been transmitted into the network core but never emerging from the network at the destination. The lost packet may be retransmitted again on an end-to-end basis in order to ensure that all data are eventually transferred from source to destination.
* The fraction of lost packets increases as the traffic intensity increases.
* Therefore, performance at a node is often measured not only in terms of delay, but also in terms of the probability of packet loss.

***

### 3. End-to-End Delay

* The end-to-end delay of sending a packet across N homogeneous links (that is, n-1 routers and two end systems) would be d<sub>end-to-end</sub> = N(d<sub>proc</sub> + d<sub>queue</sub> + d<sub>trans</sub> + d<sub>prop</sub>).
* In reality, the links will not be homogeneous and the above components will vary from one router to another, and the total end-to-end delay will be the summation of all the delays across all the routers and end-systems.

###### Traceroute
* Traceroute is a simple program that can run in any Internet host.
* When the user specifies a destination hostname, the program in the source host sends multiple, special packets toward that destination.
* As these packets work their way toward the destination, they pass through a series of routers.
* When a router receives one of these special packets, it sends back to the source a short message that contains the name and address of the router.
* Traceroute helps maps the path of the packet from the source to the destination.
* Try the following in yout terminal: `traceroute -I google.com` and see the results.
	* The program sends three packets to each router and reports the total round trip delays
	* By default, traceroute uses UDP. Using the `-I` parameter makes it use the ICMP protocol.
  	* The first hop is to 192.168.0.1 - the local router
 	* One of the next few hops will be in your ISP's network
  	* A few hops will not return any address - some firewalls block traceroute packets
  	* The final hop will be to the specified destination
  	* The image below shows few of the last hops of a traceroute query - as the queuing delay is variable, round-trip delay of packet n sent to a router n can sometimes be longer than the round-trip delay of packet n+1 sent to router n+1 (which happens between router 9 and 10). 

<img width="800" alt="image" src="https://github.com/user-attachments/assets/cc463c47-a9ff-482e-b4e9-bd3c866a1c83" />

###### End System, Application, and Other Delays
* Apart from the delays discussed, there can be additional significant delays in the end systems.
	* An end system wanting to transmit a packet into a shared medium (e.g., as in a WiFi or cable modem scenario) may purposefully delay its transmission as part of its protocol for sharing the medium with other end systems
	* Another important delay is media packetization delay, which is present in Voiceover-IP (VoIP) applications. In VoIP, the sending side must first fill a packet with
encoded digitized speech before passing the packet to the Internet, and the time to fill a packet—called the packetization delay—can be significant and can impact the user perceived quality of a VoIP call.

***

### 4. Throughput in Computer Networks

* In addition to delay and packet loss, another critical performance measure in computer networks is end-to-end throughput.
	* The instantaneous throughput at any instant of time is the rate (in bits/sec) at which the end system is receiving the file.
 	* If the file consists of F bits and the transfer takes T seconds, then the average throughput of the file transfer is F/T bits/sec.

###### Bottlenecks 
* Let R<sub>s</sub> denote the transmission rate from the server to the router and R<sub>c</sub> denote the rate from the router to the receiver. The bottleneck would be min{R<sub>s</sub>,R<sub>c</sub>}, and the throughput will be F/min(R<sub>s</sub>,R<sub>c</sub>).
* Similarly, in a network with N links, the bottleneck link will be the link with the minimum available transmission rate.
* Usually, the core of the Internet is over-provisioned with high speed links that experience little congestion, in which case, the constraining factor for throughput is typically the access network. However, that can change with increased traffic in the core.
* Suppose a user is downloading a file using a network that has the following three links:
	* Server -> Router 1 (2 Mbps)
 	* Router 1 -> Router 2 (5 Mbps)
  	* Router 2 -> Receiver (1 Mbps)
* In the above case, the access network of the reciever will be bottleneck if the entire capacity of the network is available.
* However, suppose the Router 1 -> Router 2 link is being used by 10 users (and is getting equally allocated to all), then the available capacity for this link is 500Kbps and that becomes the bottleneck for the user.
* Therefore, a link with a high transmission rate may nonetheless be the bottleneck link for a file transfer if many other data flows are also passing through that link as well.

***
